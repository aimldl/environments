README

Last updated: Mar.8, 2011 (Tue)
First written: Apr. 22, 2009 (Wed)

* OVERVIEW
  nns is a neural networks simulator of which purposes is to simulate CSRN
(Cellular Simultaneous Recurrent Network). The application for the current
version is computer Go. To learn more about CSRN, refer to 
http://http://web.mst.edu/~tk424/portal/research/CSRN/main_CSRN.htm

* HOW TO INSTALL AND UNINSTALL
  Step 1. cd to the program root directory where file "install" is located.

    $ cd root_directory

  Currently, "root_directory" is "nns-1.2". The directory name can be changed to
  any, but is recommended to keep it as it is.

  Step 2. Install or uninstall by typing:

    $ ./install
        or
    $ ./install -u

* DIRECTORY STRUCTURE
  / program_root_directory
    /archive
    /bash_scripts
    /bin
    /config_files
    /eclipse_project
    /gnuplot_config_files
    /.metadata
    /outputs
    /results
    /source_codes
      /bld_opt
      /bld_dbg

  - Program root directory
    Directory program_root_directory is the root directory for this program.
    Currently, it is named to be nns-1.2. This program works if this name is
    changed, but it is recommended to keep the name as it is.
    It contains the following files along with the sub-directories given above.
      install
      main_scrn
      nns
      README
      TODO

  - Directory bin
    Executables are stored in this directory. When "./install" is run,
    the created executables are supposed to be copied to directory bin.
    An overview of the executables are below.

    sgfc
      a program developped by Arno Hollosi which checks the SGF syntax.

    sgf2gpf 
      an utility script to convert a "single" SGF file to a corresponding 
      GSP file. SGF stands for Smart Game Format and GSP is Go Stone Positions.
      GSP is a format that only stone positions are extracted from a SGF file.
      This is necessary to to load game data in SGF by MATLAB. Note sgf2gpf
      is based on sgf2nif.

    (TODO: Finish up writing this part)

  - Directory config_files
    Configuration files called in by nns-1.2 are stored in this directory.
    A configuration file is a text file containing simulation configurations
    for nns-1.2. Refer to "HOW TO RUN THE PROGRAM" to learn more about a configuration
    file.

    One reason why a configuration file is stored in a separate directory
    is because of Eclipse. Say a configuration file is stored in a project
    directory for Eclipse explained below. On the process of using Eclipse, one 
    may mindlessly delete the directory, which will delete a configuration file 
    as well. In order to prevent this catastrophy, it is safe to maintain 
    configuration file in a separate directory dedicated to it.

  - Directories eclipse_project & .metadata
    . Project directory for Eclipse: eclipse_project
      This is a directory created by Eclipse when this program is imported to
      Eclipse. This program is originally developped without an IDE or Eclipse.
      Therefore, Makefile is used to organize the source codes. When Eclipse 
      imports the Makefile, a new project is created, resulting in a project
      directory. I just named the project directory eclipse_project.

      When Eclipse imports this program, two hidden files ".cproject" and 
      ".project" are created both in the program root directory and 
      directory "eclipse_project" (assuming the Eclipse Workspace is set to
      the program root directory.)

    . Workspace directory for Eclipse: .metadata
      This is a hidden directory created automatically by Eclipse when the 
      program root directory is set as Eclipse's workspace. It is suggested to
      switch Eclipse's workspace to the program root. In order to switch 
      workspace in Eclipse,
      
        File (menu) -> Switch Workspace

    * Comments on an IDE
      I think Eclipse is a better IDE (Integrated Development Environment)
      than the popular DDD. This program is developped mainly with Eclipse.
      I initially used a text editor and gdb, used DDD for a while, and then
      switched to Eclipse. I am most satisfied by Eclipse, so you may use
      Eclipse for this program. Refer to "HOW TO USE ECLIPSE" to learn how
      to set up to use Eclipse for this program.
  
  - Directories bash_scripts
    This directory contains bash scripts to store commands to run experiments.

  - Directory gnuplot_config_files
    This directory contains gnuplot configuration file. The extension of the file 
    is .gp that stands for g(nu)p(lot). nns-1.2 has a feature to automatically
    launch gnuplot when the simulation is done. In this occasion, a gnuplot
    configuration file in this directory is neccessary.
      Note this file is different from the program's configuration file ".cfg".
    A .cfg file is a "higher" level configuration file, which also configures 
    gnuplot's input, configuration, and output files.

  - Directory outputs
    This directory is a repository of all simulation outputs.
    Unprocessed output files from the simulator & gnuplot are stored here.

  - Directory results
    This directory stores the "final" results. Whatever results considered to be
    "final" should be moved into this directory. The purpose of doing this is
    to separate meaningful results from intermediate results stored in directory
    outputs. 

  - Directory source_codes and its subdirectories bld_opt & bld_dbg.
    Directory source_codes contains the c++ source codes.
    Directory bld_opt is a build optimized for execution.
    Directory bld_dbg is a build directory for debugging purposes.

    Directory source_codes contains the following files.
      Makefile.in
      source codes (*.cpp, *.hpp)

    Directories bld_opt & bld_dbg contain the following files.
      Makefile
      nns-1.2.exe or nns_dbg-1.2.exe (if the source codes have been compiled.)
    
    * Why the file extension .exe is used?
      "Eclipse" does not recognize an executable without file extension .exe.
      In order to use the IDE, I had to change the name.

* HOW TO RUN THE PROGRAM
  There are two different ways to run the program.

- Option 1. Run the program manually.
    The executable is located both in directory bin and directory bld_opt or bld_dbg.
  It is suggested to run one in directory bin because ones in the other directories
  may face problems with wrong directory structure.
  
  Step 1. cd to directory bin assuming you are already in the program root directory.

    $ cd bin

  Step 2. Run the program.

    $ executable (configuration file)
  
    For example, 
      $ ./nns-1.2.exe
      $ ./nns-1.2.exe default.cfg
      $ ./nns-1.2.exe default.cfg /home/tk424/2008-2010-nns/nns-1.2/outputs/2011-03-08
    
    Note the configuration file should be located in directory "config_files".

    Running without an argument will invoke the default configuration file "default.cfg".
    That is,

      $ ./nns-1.2.exe

    is equivalent to the above command.

- Option 2. Run the program with a bash script "nns.bash".
    This option is recommended when a large number of experiments needs to be run.
  This is an advanced feature of this program, so it is recommended to take this
  option after mastering how to run the program manually. The purpose of this option is
  to run experiments automatically by tweaking the design parameters.

  Step 1. Prepare a configuration file. The program should be able to run with it.
  Step 2. Decide what design parameters to tweak. Say you'd like to know the simulation
          results for different values of a parameter pso_w. For example, pso_w=0.1 
          through 1.0 with increment of 0.1.
  Step 3. Modify "modules4nns.bash". Give an option number of the -o option in 
          "nns.bash" for the chunk of lines you added/changed.
          Following the guideline in "modules4nns.bash" is suggested.
  Step 4. Run "nns.bash" with the option number of the -o option. Say the number is 3.
          In the project root directory,

            $ ./nns.bash -o 3

  Read "nns.bash" for details.

* CONFIGURATION FILE
  A configuration file is a text file that configures a simulation.
  All the parameters are set in this file.
  For example, design parameters for Neural Networks, a training algorithm, 
  e.g. PSO, input/output/configuration file for gnuplot, and output file for the
  standard output should be set in a configuration file.  
  
  - Design principle
      Neural Networks simulator is designed in a manner that all the parameters
    should be configured in a configuration file, not in the source code.
    In other words, do not hardcode the parameters in the source code.
    If a new parameter needs to be created, change Configuration.{hpp,cpp} so
    that the simulator can read the parameter from a configuration file.
      One can hard code the design parameters in the source code if one
    doesn't know how to add a parameter in the configuration file. But it is
    not suggested.

* HOW TO COMPILE THE PROGRAM MANUALLY
  There are four different ways to compile the program.
  1. Using "install" will compile the program.
  2. Using "nns.bash -m" will make/compile the program.
     Note "nns.bash -c" will "make clean".
  3. Manually compile on a terminal.
  4. Manually compile in an IDE.

  This part covers the third option.
  Step 1. cd to a build directory in the program root directory.

    $ cd build
        or
    $ cd build_dbg

  Step 2. "Make" the program.

    $ make
  
  Note "Makefile" in directory bld_opt or bld_dbg refers to Makefile.in in 
  directory source_codes. "Makefile"s in both directories differ only in
  an option 

* VERSION INFORMATION & HISTORY
- version 1.2
  Another major overhaul of the program is done.
  . The class hierarchy is changed. One of the major changes is class Myiostream.
    Previously, class SimObject was the base class. Now class Myiostream is the base
    class. Even class SimObject inherits class Myiostream.
  . A multiple number of trace files are saved thanks to class Myiostream.
    Examples of those trace files include error.prf, cell_0.trc, default.trc.
  . A different type of task is added. Currently, manually generated optimal moves 
    for the 2x2 case are trained with CNN more specifically. MCSRN (Modified CSRN).
  . MCSRN is a variant of neural network structure with input dimension reduction. 
  . The trace file structure has been changed.
  . "install" is updated. (This is 99.9% final for now.)
  . nns.bash merged main_scrn and the former has been updated.
    (nns.bash is 99.9% final for now.)
    - Now, option -e or an email notice is sent when command mail is configured properly.
    - nns.bash sources files in directory bash_scripts such as "modules4nns-single_run.bash"
      and "modules4nns-multiple_runs.bash".
- version 1.1
  A major overhaul of the program has been done.
  . The class hierarchy is changed. One of the major changes is class Cell 
    does not inherit class NeuralNetworks, but class SimObject.
- version 1.0
  . Test and release.
- version 0.9
  . Redundant lines in the source code are cleaned up.
- version 0.8
  . String counting problem.
- version 0.7
  . Successful training of test problems.
- version 0.6
  . Cellular Structure with PSO for matrix input.
- version 0.5
  . MLP with PSO for row vector input.
- version 0.4
  . Directory structure is changed.
  . Some minor changes
- version 0.3
  . System commands to launch gnuplot & gv.
- version 0.2
  . Use of a configuration file instead of hard-coded design parameters.
- version 0.1
  . Makefile, source codes, command-line arguments, etc.

* SYSTEM THAT THIS PROGRAM IS DEVELOPPED.
  GNU C++ compiler g++ version: gcc version 4.4.3 (Ubuntu 4.4.3-4ubuntu5)

  Ubuntu Linux Release 10.04 (lucid)
  Kernel Linux 2.6.32-29-generic
  GNOME 2.30.2

  Hardware
    Memory: 2G
    Processor: Intel(R) Celeron(R) CPU 540 @1.86GHz

  Note: The oldest Ubuntu version I can remember for this program is 8.4.

* HOW TO USE ECLIPSE
The following steps enable to import the existing source codes as an Eclipse project.

  1. Select "File" --> "Import" in the menu.
  2. Under C/C++, select "Existing Code as Makefile Project and hit the "Next" button.
  3. Under "Existing Code Location", hit the "Browse" button, select
     directory "source_codes" in the project root directory, and hit the "OK" button.
     In this window, there is a message "Select root directory of existing code".
     This root directory doesn't mean our project root directory.
  4. You'll see the "Project Name" is automatically filled with "source_codes".
  5. Under "Languages", uncheck "C" if you'd like.
  6. Hit the "Finish" button.

The source codes can be compiled by selecting "Project" --> "Build All".
The shortcut is "Ctrl+B".

It looks like my "Makefile" in directory "source_codes" is used to compile the source codes.
This fact has not been clarified, though. 

How to debug
  
  1. Go to "Run" --> "Debug Configurations".
  2. In the "Debug Configurations" window, the default tab is "Main".
  3. In the "Main" tab, hit the "Browse" button under "C/C++ Application:".
  4. Select "nns-1.2exe" in directory "source_codes" and hit the "OK" button.
  5. Change "Name" in the "Debug Configurations" window to "source_codes".
  6. Hit the "Apply" button. Note the source codes are automatically detected.
  7. Now the debug configuration is done. Hit the "Debug" button to debug the codes.
     The source codes should be automatically launched.
  8. Enjoy the convenient debugging features by Eclipse. :)

  - Adding a new class
    1. Select "File" --> "New" --> "Class" in the menu.
    2. Fill in the neccessary information in the "New C++ Class" and hit the "Finish" button.
    3. You'll see the header and source files are automatically generated in directory
       "source_codes" and these files are seen under the "Project Explorer". If the files are
       not shown, refresh the "source_codes" project or change the preferences.

    When a new class is added, edit "Makefile" in directory "source_codes" in order to compile
    the newly added source codes. For example, you wish to add "Sarsa.cpp".

      OBJECTS = \
         Main.cpp \
           ...
         CliffWalkingProblem.cpp

    Change the above lines to the following lines.

      OBJECTS = \
         Main.cpp \
           ...
         CliffWalkingProblem.cpp \
         Sarsa.cpp

  - Using a template
    1. Window --> Preferences.
    2. Under "Preferences" window, go to "C/C++"-> "Code Style".
    3. The code templates can be modified in the "Code Templates" tab.

* HOW TO USE ECLIPSE (Old)
  Assuming nns-1.2 is hooked up to Eclipse for the first time, there are three 
  main steps. First, create a project by importing the C++ executable 
  nns_dbg-1.2.exe which is compiled in a way to add debugging information.
  Note nns-1.2.exe cannot be used for debugging purpose because the debugging
  information is not included. So the source code cannot be seen by Eclipse.
    Secondly, configure the project by setting "Arguments" and "Source".
  Lastly, 

  Step 1. Launch Eclipse CDT. CDT needs to be installed in order to deal with
          C++. Refer to Eclipse homepage for details.
  Step 2. Create a project by importing nns_dbg-1.2.exe.
          . Select "File"->"Import" menu. Then "Import" Window will pop up.
          . Select C/C++ - C/C++ Executable. Click the "Next" button.
          . In the "Import Executable" window, click the "Browse" button.
            Find and select "nns_dbg-1.2.exe" in directory bin of the project directory.
          . Click "Next". "New project name:" is set to "eclipse_project". 
            The Eclipse project files will be stored in directory "eclipse_project".
            Note Eclipse creates a directory named as the string in "New project name:".
            For example, if the project name is "Debug_nns-1.2.exe", a new directory
            "Debug_nns-1.2.exe" is created and all the project files are stored in this
            directory. The project name "eclipse_project" is suggested, but ,in fact,
            not a must to use Eclipse.
          . Change the name to your own name if you want, e.g. nns-1.2.
          . Click "Finish" button. Note the "Next" button is deactivated.
  Step 3. Set the command line arguments to the configuration file.
          . Now a new window "Debug Configurations" pops up.
            The majority of the window (right side) is used to display tabs.
            Those tabs (from left) are Main, Arguments, Environment, Debugger, 
            Source, and Common.
          . Select "Arguments" tab.
          . Type in the configuration file name under "Program arguments".
            The "Program arguments" is the command line arguments that the program
            or the executable takes in.
              For example, "default.cfg" or try "../config_files/default.cfg"
            Say your program name is "nns_dbg-1.2.exe" and your "Program arguments" is
            "default.cfg". Then this is equivalent to "$ nns_dbg-1.2.exe default.cfg"
            in the command line.
        . Ensure "Use default" is checked.
  Step 4. Make the source codes visible to Eclipse. Equivalently, set the "Source"
          tab as "Path Mapping".
          . Select "Source" tab. You will see "Dafault" under "Source Lookup Path:".
          . Select "Default" and click "Add" button.
          . Select "Path Mapping" & hit "OK" button. Then "Path Mappings" window pops up. 
            If not, select "Path Mapping:New Mapping" in "Source Lookup Path:"
            and then click "Edit" button on the right.
          . Hit "Add" button. Then in the "Path Mappings" window,
            a new window "Modify the path mappings" may pop up.
          . Add the directory location where the source codes are located.
          . Click the area right below "Local file system path:", then the "Browse"
            icon or a small box with "..." will appear on the right. Hit the icon and 
            select directory source_codes under the program root directory.
          . Copy the same path manually to "Compilation path:" and hit "OK" buttons.
            (I'm not sure if this step is necessary, but the "OK" button is
            not highlighted without doing this.)
          . Hit the "OK" button in the "Path Mappings" window.
          . You'll see "Path Mapping: New Mapping" above "Default in "Source Lookup Path"
            textbox.
  Step 5. Click the "Apply" button in the "Debug Configurations" window.
          You may see a message "Create Launch Configuration" on the right bottom of 
          the Eclipse main window.
  Step 6. Click "Debug" button.
          I see an error message with three buttons.

          Can't find a source file at "../Main.cpp" 
          Locate the file or edit the source lookup path to include its location.

          "View Disassembly..."
          "Locate File..."
          "Edit Source Lookup Path..."

          I hit "Locate File..." and select "Main.cpp" in directory source_codes.
          Then the source code can be seen.

  Step 7. Click "Run" in the Menu and then "Run Configurations".
          "Run Configurations" window will pop up.

* How to compile with Eclipse
  Currently, this doesn't work, so I compile the program in the terminal.
  The following comments are invalid, but I'll keep them as they are for a possible
  future use.

------------------------------------------------------------------------------------
  The Makefile is located under a sub-directory "build" and "build_full", 
  so Project->Build-All or Ctrl+B doesn't compile the source codes.
  What should I do?

  Say your project name is "source_codes", then you should see a list of directories
  and files similar to below in the "Project Explorer".

  - source_codes
     > build
     > build_full
     * Api.cpp
     * Api.hpp
         ...
     * TrainingAlgorithms.cpp
     * TrainingAlgorithms.hpp
     * Makefile.in

   Your "Makefile"s are located in directories "build" and "build_full".
   Note both of them work refer to Makefile.in, but the a few parameters are different.
   They can be compiled simultaneously.

   To compile this project with one of the "Makefile"s, right-click the file and select
   " Run As"=>"Run Configurations".
   If "Run Configurations" is configured properly and you hit the "Run" button, the project
   will compile. Then the question is how to configure it properly.
   Click "Arguments" tab and type in the relative location of the config file in "Program 
   arguments". For example, "../config_files/default.cfg". The rest of config uses the
   default settings.
------------------------------------------------------------------------------------

* GNUPLOT
  gnuplot is a plotting tool. It is not a standard command in Ubuntu Linux 8.4,
  so it should be installed manually.
  
  - Installation
    Refer to Ubuntu Linux manual.

  - Prerequisite
    The gnuplot needs to be turned on in the configuration file.
    For example, the configuration file should include the following lines.

      gnuplot_run               = 1
      gnuplot_title             = my_first_plot
      gnuplot_range_x_from      = -3.0
      gnuplot_range_x_to        =  3.0
      gnuplot_range_x_increment =  0.5    

  - Message for successful run

      GNU Plot is successfully run.

    The above message is created by gnuplot when gnuplot runs successfully.
    This message will be saved in an output file. 
      
    For example, assuming the default output file "default.out" is used.
    The following lines are stored in the output file.
    
     GNU Plot is successfully run. 
       Use a command gv to check a postscript file (*.ps). 
   
    Note a command gv (Ghost Viewer) is also run by the simulator.
    In other words, the simulator launches the two system commands automatically.
   
     $ gnuplot gnuplot_default_config.gp
     $ gv gnuplot_default_output.ps

   The system commands are stored in the output file.
   
     systemCommandRunGnuplot_ = 'gnuplot gnuplot_default_config.gp'
     systemCommandRunGnugv_   = 'gv gnuplot_default_output.ps'
   
  - Error message
    When gnuplot fails, an error message is stored in the output file.
    For example,
    
      Non-zero value (256) is returned. 
      Possible causes for this error include: 
        1. GNU Plot is not installed, 
        2. GNU Plot configuration file name (*.gp) is incorrect, 
        3. GNU Plot execution failed. 

* TEST PROBLEMS
  Several test problems are employed to correctly implement Neural Networks
  architecture/structure and training algorithms.
  It is crucial to implement each element of a CSRN correctly because
  finding bugs in the complex CSRN system is a challenging and time-consuming
  task.
  
  Do not be confused with MODE_TEST and MODE_NORMAL.
  Both of them can be used for test_problem-1, for example.
  The former is used to test NeuralNets by "fixing" the weights;
  the latter randomizes neural network weights.
  
  - Test problem 1: Training a simple quadratic function with MLP-PSO
    The target function, y=2x^2+1 x=[-1,1].
    Number of samples on x axis = 11
    
    . FFNN (Feed-Forward Neural Nets) or MLP (Multi-Layer Perceptron)
      2x5x1
      Number of input layer neurons  = 2
      Number of hidden layer neurons = 5
      Number of output layer neuron  = 1
      Bias = 1
      Transfer function = logsig, a=1, i.e. f(x)=1/(1+e^(-x));
    . PSO (Particle Swarm Optimization)
      Two equations in PSO are:
      
      V_id = w*V_id + c1*rand1*(P_best_id - X_id) + c2*rand2*(G_best_id - X_id);
      X_id = X_id + V_id;
     
      where V_id & X_id are the velocity & location of a particle, respectively.
      P_best is the particle's best,
      G_best is the global best.
    
      Use the following parameters
        Number of particles = 40 to 45, so set it to 40.
        w=0.7, c1=1.9, c2=2.0
      Previous experiment in Matlab shows these parameters work the best.
      So, use a set of parameters that is proved to work.
    . Epochs or number of iterations.
      n=100,
      The target MSE (Mean Square Error) should reach about 0.001.

* USEFUL COMMANDS
  awk
  bash
  find
  g++
  gprof     GNU profiler shows the profile of a program
  grep      
  valgrind  Checks the memory leak of a program
  scp
    - Upload to the client
      Assume a file "filename" in the host (your computer) needs to be
      uploaded to the client (cuda-cluster.mst.edu).

        $ scp filename account@cuda-cluster.mst.edu:~/directory
        account@cuda-cluster.mst.edu's password: 
        filename                                100%   10MB  10.2MB/s   00:01    
        $

    - Download from the client
      Assume a file "filename" in the client (cuda-cluster.mst.edu) needs to be
      downloaded to the current directory "." in the host (your computer).

        $ scp account@cuda-cluster.mst.edu:~/directory/filename .
        account@cuda-cluster.mst.edu's password: 
        filename                                100%   10MB  10.2MB/s   00:01    
        $

  ssh
    ssh cuda-cluster.mst.edu
  xargs


* Unicode
Refer to the following links.

http://en.wikipedia.org/wiki/List_of_Unicode_characters
http://en.wikipedia.org/wiki/Arrow_(symbol)

From http://stackoverflow.com/questions/1799063/how-can-i-display-unicode-characters-in-a-linux-terminal-using-c

U+2588	█	Full block

Question: I'm working on a chess game in C++ on a linux environment and I want to display the pieces using unicode characters in a bash terminal. Is there any way to display the symbols using cout?

An example that outputs a knight would be nice: ♞ = U+265E.

Answer:
To output Unicode characters you just use output streams, the same way you would output ASCII characters. You can store the Unicode codepoint as a multi-character string:

 std::string str = "\u265E";
 std::cout << str << std::endl;
It may also be convenient to use wide character output if you want to output a single Unicode character with a codepoint above the ASCII range:

 setlocale(LC_ALL, "en_US.UTF-8");
 wchar_t codepoint = 0x265E;
 std::wcout << codepoint << std::endl;
However, as others have noted, whether this displays correctly is dependent on a lot of factors in the user's environment, such as whether or not the user's terminal supports Unicode display, whether or not the user has the proper fonts installed, etc. This shouldn't be a problem for most out-of-the-box mainstream distros like Ubuntu/Debian with Gnome installed, but don't expect it to work everywhere.




-------------------------------------------------------------------------
            An example configuration file: default.cfg
-------------------------------------------------------------------------
# mcsrn_wt_idr_2x2.cfg
#
# Modified CSRN (MCSRN) with input dimension reduction for a 2x2 board.
# The multivalued function is transformed into a single-valued function.
#
# Last updated: Mar. 4, 2011 (Fri)
# First written: May 25, 2009 (Mon)
#
# Examples:
#   No space is allowed a in variable name
#     simul_task_id = 2
#     pso_p_best_initial_value = inf
# Do not use ";" at the end of the line.
#   Examples. The following lines are wrong.
#     simul_task_id = 2;
#     pso_p_best_initial_value = inf;
#
#   For a boolen type variable of which option is limited only to on or off,
# do not use "true" or "false", rather use 0 or 1 unless it's specified.
#
# Refer to the manual for details.
################################################################################
#                            ConfigDirStruct                                   #
################################################################################
# Default values
#
# dir_outputs             = outputs
# dir_gnuplot_config_file = gnuplot_config_files
# file_trace              = default.trc
# file_error_profile      = error.prf
# file_nn_weights         = nnets_weights.cnn
# file_nn_init_weights    = initial_weights.cnn
#
# Note "file_nn_weights" is a file for neural networks weights.
#
# Options for possible variables
#
# file_gnuplot_input
#    a text file with data to plot. Use .dat for file extension.
# file_gnuplot_config
#    File extension is ".gp" meaning g(nu)p(lot).
# file_gnuplot_output
#    File extension is ".ps" or p(ost)s(cript).
#    Ensure gnuplot_"file_gnuplot_output" matches the output file name in 
#    "file_gnuplot_config."
#
# Assumption
#    1. The directores specified by this program have already been made.
#    2. File names except trace files should exist in the designated locations.
# Default values: directory structure and file names
#    The default directory structure and file names are set in the source code,
#    i.e. void Myiostream::setDefaultValues(). Class ConfigDirStruct provides
#    flexibility to change the directory & file names in the configuration file.
# cwd (Current Working Directory)
#    cwd is displayed in the terminal when the program is run. 
# Directory for a config file: directory config_files
#    It should be hard-coded in the source code or a config file cannot be read.

file_nn_init_weights = weights0121_2011.cnn
file_gnuplot_input   = gnuplot_test_input.dat
file_gnuplot_config  = gnuplot_default_config.gp
file_gnuplot_output  = gnuplot_test_output.ps

################################################################################
#                               ConfigData                                     #
################################################################################
# About input, output, target data
# test_problem-1:
#   x = [-1.0:0.1:1.0], y = 2.0*x^2-1.0;
# Note for "y = 2.0*x^2+1.0;", there is no way for NNs output to reach y=3.0
# because y_hat is bound to [-1.0, 1.0].
#
# Options for possible variables
#
# data_input_config: e.g. 2:2:16
# data_target_config: 

# data_representation: ternary
# data_representation_offset: 0.0, 1.0
# data_type: board_status_sequences, single_valued_function, multi_valued_function

data_representation        = ternary
data_representation_offset = 1.0
data_type                  = board_status_sequences

################################################################################
#                           ConfigSimulations                                  #
################################################################################
# Options for possible variables
#
# simul_task_type: cmlp_string_count, learn_optimal_moves, plot_act_fn_mod_3, test_ter2bin
#    Use "learn_optimal_moves" to train CNN for the Go data.
#    Note: if simul_task_type = plot_act_fn_mod_3, most of the options are disabled.
# simul_boardSize: 2
#   The program is designed only for 2 now.
# simul_trace_all: 0 (off), 1 (on).        Typicall, this is turned off.
# simul_trace_on: 0 (off), 1 (on).         Typicall, this is turned off.
# simul_postprocess: 0 (off), 1 (on).      Typicall, this is turned off.
# simul_show_progress_bar: 0 (off), 1 (on) Typicall, this is turned on.
# simul_player: black, white
#   The input data is separated for black and white Go player.
#   The CNN should be trained separately for each player.
# simul_data_type: single_valued_function, multi_valued_function

simul_task_type           = learn_optimal_moves
simul_postprocess         = 0
simul_show_progress_bar   = 1
simul_boardSize           = 2
simul_player              = black

# Design issue: simul_boardSize & simul_player may be in a new class ConfigBaduk.
# Leave them because there aren't many variables to configure the Baduk games now.

################################################################################
#                               ConfigCnn                                      #
################################################################################
# Options for possible variables
#
# cnn_nn_type: cmlp, cpsrn, csrn, mcsrn
#    mcsrn automatically uses the input dimension reduction technique.
# cnn_max_epoch_o: any positive integer number
#    The maximum number of epochs for the outer loop
# cnn_max_epoch_i: any positive integer number
#    The maximum number of epochs for the inner loop
# cnn_target_system_error: any non-negative real value
#    Target error for the outer loop.
# cnn_target_cell_error: any non-negative real value
#    Target error for the inner loop within cells.
#    Set this value to "-1.0" so the soft hibernation problem can be avoided.
# cnn_fd_input_initialization: zeros, ones, random, target,rand_ternary
#    CMLP does not use this parameter. It is for cnn_nn_type with recurrence or
#    feedback input(s).
#    - zeros
#      is not much different from random. After the first internal loop, the
#      output is computed by the neural networks' weights. If the neural networks
#      weights are randomized, the first neural networks output is more or like
#      random.
#    - target
#      is to set the initial values to the target values.
#    - ones
#      This is my favorite initialization method so far.
# cnn_error_metric: mse, abs_error
#    mse (Mean Square Error)
#    abs_error (Absolute Error) error=abs(target data-estimated data)
# cnn_training_algorithm: pso
# cnn_match_init_weights_to_training_algo: 0 (off), 1 (on)
#       Say CNN's initial weights are randomized. These weights are matched to the 
#    training algorithm. For example, PSO's initial particle locations are set by
#    CNN's corresponding weights. 
# neuralnets_initial_weights_mode: random, load_manually
#    A variable "file_nn_weights" is important for both options.
#       For example, "file_nn_weights = weights.cnn". 
#    random: the randomized initial weights are saved in "file_nn_weights".
#               The usefulness of this feature is questionable at first sight 
#            because PSO randomizes CNN's weights anyways. There is a fundamental 
#            difference here, though. If we let PSO randomizes CNN's initial 
#            weights, what actually happens is PSO selects the best particle's 
#            position as initial weights. 
#               Stricly speaking, this initial weights are ones after one epoch 
#            of training. Letting PSO initialize the weights is not random 
#            strictly speaking. Therefore, CNN should allow the random CNN weights
#            overload the initial PSO's best particle's position. Namely CNN should
#            not let PSO overtake the CNN's initialization. Otherwise, PSO's 
#            best particle's position after one epoch will mistakenly initialize
#            CNN's weights.
#    load_manually: the initial weights in "file_nn_weights" are loaded as the
#       weights in class NeuralNetworks. Therefore CNN can start from the 
#       same weights with this option. This feature is incorporated to repeat 
#       experiments with identical initial weights.
#          CNN's internal behavior is so strongly interwound that understanding the 
#       behavior is complex. Therefore, it is often neccessary to start from identical 
#       initial weights in order to reduce the dynamics of starting from different 
#       initial weights at each run of simulations.

cnn_nn_type                             = mcsrn
cnn_training_algorithm                  = pso
cnn_error_metric                        = abs_error
cnn_target_system_error                 = 0.0
cnn_target_cell_error                   = -1.0
cnn_fd_input_initialization             = ones
cnn_max_epoch_o                         = 10000
cnn_max_epoch_i                         = 500
cnn_match_init_weights_to_training_algo = 1
cnn_initial_weights_mode                = load_manually

################################################################################
#                          ConfigNeuralNetworks                                #
################################################################################
# Options for possible variables
#
# neuralnets_number_of_neurons_in_layers: any non-negative integer separated by colon ":".
#    For example, "neuralnets_number_of_neurons_in_layers = 6:1". "6:1" means 
#    N input layer nodes, 6 hidden layer neurons & 1 output neuron.
#    The number of input layer nodes is supposed to be determined automatically
#    by the input data size. Read below for further explanation.
#      It supports any number of neurons with any number of layers because this 
#    is implemented with a container vector. Related variables such as
#    the number of hidden layers are automatically computed, too.
#      Note "neuralnets_number_of_nodes_in_layers" is obsolete because the number
#    of input layer nodes may vary in the CNN architecture. An example for this
#    is "neuralnets_number_of_nodes_in_layers = 6:6:1". 6 input layer nodes,
#    6 hidden layer neurons & 1 output neuron.
#
#    Be careful not to include the number of input nodes because it will be 
#    determined by other factors such as the board size and a cell structure, 
#    e.g. MLP or SRN.
#      For example, MCSRN for the 2x2 uses the input dimension reduction. 
#    The number of nodes in the input layer is 3, so the the neural networks
#    architecture with "neuralnets_number_of_neurons_in_layers = 2:1" becomes
#    "3:2:1". Be careful not to set "neuralnets_number_of_neurons_in_layers" to
#    "neuralnets_number_of_neurons_in_layers = 3:2:1". This setting is wrong
#    because the hidden layer has three neurons and the output layer has two
#    neurons.
#
#      Note a node is a super set of a neuron. A neuron is an elementary 
#    computational unit. For example, a neuron performs linear combination
#    followed by an activation function. A node is a point in a graph model
#    to depict a neural network. When the point can be a neuron or just a point
#    to bypass a data. The input nodes do not perform any computation, rather
#    they bypass the given data. 
# neuralnets_activation_function: linear, tansig, logsig, floor, ternary_step, mod_3
#       output layer activation fn    activation fn for the rest of them
#   1            linear                           tansig
#   2            linear                           logsig
#   3            tansig                           tansig
#   4            logsig                           logsig
#   5            floor                            tansig 
#   6            ternary_step                     tansig
#   7            ternary_step                     logsig
#   8            mod_3                            tansig
#   9            mod_3                            logsig
#   Range of the activation output
#     tansig: a real value in [-1,1] 
#     logsig: a real value in [0,1]
#     ternary_step: an integer value in [0,2]
#     mod_3: an integer value in [0,2]
# neuralnets_activation_function_hidden_layer: linear, tansig, logsig, floor, ternary_step, mod_3
#   This substitutes "neuralnets_activation_function" and manually set activation 
#   function in the hidden layer(s).
# neuralnets_activation_function_output_layer: linear, tansig, logsig, floor, ternary_step, mod_3
#   This substitutes "neuralnets_activation_function" and manually set activation 
#   function in the output layer.
# neuralnets_slope_param_logsig: any real number
#    For example, "neuralnets_slope_param_logsig = 1.0".
# neuralnets_slope_param_tansig: any real number
#    For example, "neuralnets_slope_param_tansig = 1.0".
#
# Variables only for ternary_step activation function
#   c is the center of the step function and w is the width.
# neuralnets_ternary_step_function_c: any real number
#    For example, "neuralnets_ternary_step_function_c = 10.0"
# neuralnets_ternary_step_function_w: any real number
#    For example, "neuralnets_ternary_step_function_c = 10.0"

neuralnets_number_of_neurons_in_layers      = 7:1
neuralnets_activation_function_hidden_layer = tansig
neuralnets_activation_function_output_layer = mod_3
neuralnets_slope_param_logsig               = 1.0
neuralnets_slope_param_tansig               = 1.0

################################################################################
#                               ConfigPso                                      #
################################################################################
# These parameters configures the PSO particles' behavior in each cell. Note
# an instance of class Pso resides in a cell.
#
# Options for possible variables
#
# pso_number_of_particles: any non-negative integer value, e.g. 50
#    Be careful not to set "pso_number_of_particles=1".
# pso_w: any real value between 0.0 and 1.0, e.g. 0.2
# pso_c1: any real value, in the original PSO paper, this value is set to 2.0
# pso_c2: any real value, in the original PSO paper, this value is set to 2.0
# pso_v_max: any real value, e.g. 2.0
# pso_x_min: any real value, e.g. -100.0
# pso_x_max: any real value, e.g. 100.0
# pso_v_initial_value: any real value, e.g. 0.000000000000001
#   Don't set it to zero or the initial V_[i] to zero. When the initial velocity
#   is set to zero, the velocity will be frozen to zero all the time because
#   the globally best particle stops moving around.
#      If you don't like a large value, pick a small value around zero.
# pso_global_best_initial_value: inf, cnn, or any floating number.
#    When pso_global_best_initial_value=inf, the first particle's position becomes
#    the global best's position. So pso_global_best_initial_value should be inf 
#    in order for PSO to work properly. Note, however, this setting is for the 
#    conventional neural networks.
#
# pso_use_particle_history_reset: 0 (off), 1 (on)
#      This is a new feature for our novel PSO algorithm or RPSO (Recurrent PSO).
#    The history or the particle best for non-best particles is reset/reinitialized.
#    Note a multiple number of particles can have the same fitness. In this case,
#    the history of all these particles are kept. That of the rest of particles is
#    reset. 

pso_number_of_particles        = 1000
pso_w                          = 0.10
pso_c1                         = 1.0
pso_c2                         = 1.0
pso_v_max                      = 1.0
pso_x_min                      = -500.0
pso_x_max                      = 500.0
pso_v_initial_value            = 0.000000000000001

pso_use_particle_history_reset = 1

################################################################################
#                             ConfigGnuPlot                                    #
################################################################################
# Options for possible variables
#
# gnuplot_run: 0 (off), 1 (on)
#    Setting it to 1 automatically launches GNU plot after running a simulation.
# gnuplot_title
# gnuplot_range_x_from
# gnuplot_range_x_to
# gnuplot_range_x_increment

gnuplot_run               = 0
gnuplot_title             = my_first_plot
gnuplot_range_x_from      = -3.0
gnuplot_range_x_to        =  3.0
gnuplot_range_x_increment =  0.5
-------------------------------------------------------------------------
(END OF README)

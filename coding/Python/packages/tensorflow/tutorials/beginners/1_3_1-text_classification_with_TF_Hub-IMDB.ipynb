{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### aimldl >python3 > packages > tensorflow > tutorials > beginners > 1_3_1-text_classification_with_TF_Hub-IMDB.ipynb\n",
    "\n",
    "* This notebook is a replica of [Text classification with preprocessed text: Movie reviews](https://www.tensorflow.org/tutorials/keras/text_classification_with_hub) with some comments.\n",
    "  * [TensorFlow](https://www.tensorflow.org/) > [Learn](https://www.tensorflow.org/learn) > [TensorFlow Core](https://www.tensorflow.org/overview) > [Tutorials](https://www.tensorflow.org/tutorials) > ML basics with Keras > [Text classification with preprocessed text](https://www.tensorflow.org/tutorials/keras/text_classification_with_hub)\n",
    "* It is prerequisite to install TensorFlow 2.0 & Keras."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text classification with preprocessed text: Movie reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook classifies movie reviews as positive or negative using the text of the review. This is an example of binary—or two-class—classification, an important and widely applicable kind of machine learning problem.\n",
    "\n",
    "The tutorial demonstrates the basic application of transfer learning with TensorFlow Hub and Keras.\n",
    "\n",
    "We'll use the IMDB dataset that contains the text of 50,000 movie reviews from the Internet Movie Database. These are split into 25,000 reviews for training and 25,000 reviews for testing. The training and testing sets are balanced, meaning they contain an equal number of positive and negative reviews."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prerequisite: Install tensorflow-hub & tensorflow-datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q tensorflow-hub\n",
    "!pip install -q tensorflow-datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version:  2.0.0\n",
      "Eager mode:  True\n",
      "Hub version:  0.7.0\n",
      "GPU is NOT AVAILABLE\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "print(\"Version: \", tf.__version__)\n",
    "print(\"Eager mode: \", tf.executing_eagerly())\n",
    "print(\"Hub version: \", hub.__version__)\n",
    "print(\"GPU is\", \"available\" if tf.config.experimental.list_physical_devices(\"GPU\") else \"NOT AVAILABLE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the IMDB dataset\n",
    "#### TensorFlow Dataset\n",
    "[Module: tfds](https://www.tensorflow.org/datasets/api_docs/python/tfds) or tensorflow_datasets is TensorFlow's Dataset API which defines a collection of datasets ready-to-use with TensorFlow.\n",
    "\n",
    "#### tfds.load\n",
    "[tfds.load](#https://www.tensorflow.org/datasets/api_docs/python/tfds/load) loads the named dataset into a [tf.data.Dataset](#https://www.tensorflow.org/api_docs/python/tf/data/Dataset). In this example, \"name\" is \"imdb_reviews\", \"as_supervised\" is set to \"True\", and \"split\" specifies how to split the entire IMDB dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### name\n",
    "\"name\" is a string of the registered name. It can be either \"dataset_name\" or \"dataset_name/config_name\".\n",
    "\n",
    "##### as_supervised\n",
    "The default value is False. If \"as_supervised\" is True, [tf.data.Dataset](#https://www.tensorflow.org/api_docs/python/tf/data/Dataset) become a 2-tuple structure of (input, lable).\n",
    "\n",
    "##### split\n",
    "The default value is None which returns a dict with all splits of the dataset. Typically, it is specified to [tdfs.Split.TRAIN](https://www.tensorflow.org/datasets/api_docs/python/tfds/Split#TRAIN) and [tfds.Split.TEST](#https://www.tensorflow.org/datasets/api_docs/python/tfds/Split#TEST). The list of class members are:\n",
    "* ALL\n",
    "* TEST\n",
    "* TRAIN\n",
    "* VALIDATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all test train validation\n"
     ]
    }
   ],
   "source": [
    "print( tfds.Split.ALL, tfds.Split.TEST, tfds.Split.TRAIN, tfds.Split.VALIDATION )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NamedSplitAll()"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfds.Split.ALL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NamedSplit('test')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfds.Split.TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NamedSplit('train')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfds.Split.TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NamedSplit('validation')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfds.Split.VALIDATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow_datasets.core.splits.NamedSplitAll"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(tfds.Split.ALL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow_datasets.core.splits.NamedSplit"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(tfds.Split.TEST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow_datasets.core.splits.NamedSplit"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(tfds.Split.TRAIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow_datasets.core.splits.NamedSplit"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(tfds.Split.VALIDATION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the training set into 60% and 40%, so we'll end up with 15,000 examples\n",
    "# for training, 10,000 examples for validation and 25,000 examples for testing.\n",
    "train_validation_split = tfds.Split.TRAIN.subsplit( [6, 4] )\n",
    "\n",
    "(train_data, validation_data), test_data = tfds.load( \n",
    "    name=\"imdb_reviews\", \n",
    "    split=(train_validation_split, tfds.Split.TEST),\n",
    "    as_supervised=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last message specifies the location of the downloaded data:\n",
    "> Dataset imdb_reviews downloaded and prepared to /home/aimldl/tensorflow_datasets/imdb_reviews/plain_text/0.1.0.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a closer look at \n",
    "> split=(train_validation_split, tfds.Split.TEST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(NamedSplit('train')(tfds.percent[0:60]),\n",
       " NamedSplit('train')(tfds.percent[60:100]))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_validation_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tuple"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type( train_validation_split )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The IMDB data is split into training, validation, and test data. The ratio of training and validation data is 60% and 40% from the train data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_OptionsDataset shapes: ((), ()), types: (tf.string, tf.int64)>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.data.ops.dataset_ops._OptionsDataset"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type( train_data )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_OptionsDataset shapes: ((), ()), types: (tf.string, tf.int64)>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.data.ops.dataset_ops._OptionsDataset"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type( validation_data )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore the data\n",
    "#### 0 -> Negative & 1 -> Positive\n",
    "The label is either 0 or 1 where 0 is a negative review and 1 is a positive review. \n",
    "\n",
    "#### First 10 Examples\n",
    "train_data.batch(10) fetches the first 10 examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=640, shape=(10,), dtype=int64, numpy=array([1, 1, 1, 1, 1, 1, 0, 1, 1, 0])>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_examples_batch, train_labels_batch = next( iter(train_data.batch(10)) )\n",
    "train_labels_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Among them, the labels & data of the first example are printed below. train_labels_batch[0] shows the first label is \"1\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=288, shape=(), dtype=int64, numpy=1>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels_batch[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data or review of the first example is train_examples_batch[0]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=274, shape=(), dtype=string, numpy=b\"As a lifelong fan of Dickens, I have invariably been disappointed by adaptations of his novels.<br /><br />Although his works presented an extremely accurate re-telling of human life at every level in Victorian Britain, throughout them all was a pervasive thread of humour that could be both playful or sarcastic as the narrative dictated. In a way, he was a literary caricaturist and cartoonist. He could be serious and hilarious in the same sentence. He pricked pride, lampooned arrogance, celebrated modesty, and empathised with loneliness and poverty. It may be a clich\\xc3\\xa9, but he was a people's writer.<br /><br />And it is the comedy that is so often missing from his interpretations. At the time of writing, Oliver Twist is being dramatised in serial form on BBC television. All of the misery and cruelty is their, but non of the humour, irony, and savage lampoonery. The result is just a dark, dismal experience: the story penned by a journalist rather than a novelist. It's not really Dickens at all.<br /><br />'Oliver!', on the other hand, is much closer to the mark. The mockery of officialdom is perfectly interpreted, from the blustering beadle to the drunken magistrate. The classic stand-off between the beadle and Mr Brownlow, in which the law is described as 'a ass, a idiot' couldn't have been better done. Harry Secombe is an ideal choice.<br /><br />But the blinding cruelty is also there, the callous indifference of the state, the cold, hunger, poverty and loneliness are all presented just as surely as The Master would have wished.<br /><br />And then there is crime. Ron Moody is a treasure as the sleazy Jewish fence, whilst Oliver Reid has Bill Sykes to perfection.<br /><br />Perhaps not surprisingly, Lionel Bart - himself a Jew from London's east-end - takes a liberty with Fagin by re-interpreting him as a much more benign fellow than was Dicken's original. In the novel, he was utterly ruthless, sending some of his own boys to the gallows in order to protect himself (though he was also caught and hanged). Whereas in the movie, he is presented as something of a wayward father-figure, a sort of charitable thief rather than a corrupter of children, the latter being a long-standing anti-semitic sentiment. Otherwise, very few liberties are taken with Dickens's original. All of the most memorable elements are included. Just enough menace and violence is retained to ensure narrative fidelity whilst at the same time allowing for children' sensibilities. Nancy is still beaten to death, Bullseye narrowly escapes drowning, and Bill Sykes gets a faithfully graphic come-uppance.<br /><br />Every song is excellent, though they do incline towards schmaltz. Mark Lester mimes his wonderfully. Both his and my favourite scene is the one in which the world comes alive to 'who will buy'. It's schmaltzy, but it's Dickens through and through.<br /><br />I could go on. I could commend the wonderful set-pieces, the contrast of the rich and poor. There is top-quality acting from more British regulars than you could shake a stick at.<br /><br />I ought to give it 10 points, but I'm feeling more like Scrooge today. Soak it up with your Christmas dinner. No original has been better realised.\">"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_examples_batch[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can you read the review and see if this review is positive? The review starts off from disappointment, but ends up giving 10 points. So this review is positive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanduing the Loaded Data\n",
    "This section doesn't exit in the TensorFlow tutorial, but I think it's necessary.\n",
    "TODO:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.data.ops.dataset_ops._OptionsDataset"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type( train_data )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.framework.ops.EagerTensor"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type( train_examples_batch )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.framework.ops.EagerTensor"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type( train_labels_batch )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type( train_data.batch(10)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next( iter(train_data.batch(10)) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Representation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a Keras layer that uses a TensorFlow Hub model to embed the sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=468, shape=(3, 20), dtype=float32, numpy=\n",
       "array([[ 3.9819887 , -4.4838037 ,  5.177359  , -2.3643482 , -3.2938678 ,\n",
       "        -3.5364532 , -2.4786978 ,  2.5525482 ,  6.688532  , -2.3076782 ,\n",
       "        -1.9807833 ,  1.1315885 , -3.0339816 , -0.7604128 , -5.743445  ,\n",
       "         3.4242578 ,  4.790099  , -4.03061   , -5.992149  , -1.7297493 ],\n",
       "       [ 3.4232912 , -4.230874  ,  4.1488533 , -0.29553518, -6.802391  ,\n",
       "        -2.5163853 , -4.4002395 ,  1.905792  ,  4.7512794 , -0.40538004,\n",
       "        -4.3401685 ,  1.0361497 ,  0.9744097 ,  0.71507156, -6.2657013 ,\n",
       "         0.16533905,  4.560262  , -1.3106939 , -3.1121316 , -2.1338716 ],\n",
       "       [ 3.8508697 , -5.003031  ,  4.8700504 , -0.04324996, -5.893603  ,\n",
       "        -5.2983093 , -4.004676  ,  4.1236343 ,  6.267754  ,  0.11632943,\n",
       "        -3.5934832 ,  0.8023905 ,  0.56146765,  0.9192484 , -7.3066816 ,\n",
       "         2.8202746 ,  6.2000837 , -3.5709393 , -4.564525  , -2.305622  ]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding = \"https://tfhub.dev/google/tf2-preview/gnews-swivel-20dim/1\"\n",
    "hub_layer = hub.KerasLayer( embedding, input_shape=[], dtype=tf.string, trainable=True )\n",
    "hub_layer( train_examples_batch[:3] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the output shape of the embeddings is fixed to (num_examples, embedding_dimension) regardless of the input text length."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the model\n",
    "TODO: Rewrite the following excerpt of the tutorial.\n",
    "The layers are stacked sequentially to build the classifier:\n",
    "\n",
    "* The first layer is a TensorFlow Hub layer.\n",
    "  * This layer uses a pre-trained Saved Model to map a sentence into its embedding vector. The pre-trained text embedding model that we are using (google/tf2-preview/gnews-swivel-20dim/1) splits the sentence into tokens, embeds each token and then combines the embedding. The resulting dimensions are: (num_examples, embedding_dimension).\n",
    "* This fixed-length output vector is piped through a fully-connected (Dense) layer with 16 hidden units.\n",
    "* The last layer is densely connected with a single output node.\n",
    "  * Using the sigmoid activation function, this value is a float between 0 and 1, representing a probability, or confidence level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "keras_layer (KerasLayer)     (None, 20)                400020    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 16)                336       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 400,373\n",
      "Trainable params: 400,373\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add( hub_layer )\n",
    "model.add( tf.keras.layers.Dense(16, activation='relu') )\n",
    "model.add( tf.keras.layers.Dense(1, activation='sigmoid') )\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile( optimizer='adam',\n",
    "               loss='binary_crossentropy',\n",
    "               metrics=['accuracy'] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "30/30 [==============================] - 3s 86ms/step - loss: 0.7603 - accuracy: 0.5375 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/20\n",
      "30/30 [==============================] - 2s 69ms/step - loss: 0.6293 - accuracy: 0.6585 - val_loss: 0.6055 - val_accuracy: 0.6852\n",
      "Epoch 3/20\n",
      "30/30 [==============================] - 2s 69ms/step - loss: 0.5856 - accuracy: 0.7055 - val_loss: 0.5722 - val_accuracy: 0.7156\n",
      "Epoch 4/20\n",
      "30/30 [==============================] - 2s 69ms/step - loss: 0.5516 - accuracy: 0.7385 - val_loss: 0.5409 - val_accuracy: 0.7409\n",
      "Epoch 5/20\n",
      "30/30 [==============================] - 2s 67ms/step - loss: 0.5138 - accuracy: 0.7661 - val_loss: 0.5091 - val_accuracy: 0.7629\n",
      "Epoch 6/20\n",
      "30/30 [==============================] - 2s 70ms/step - loss: 0.4797 - accuracy: 0.7929 - val_loss: 0.4776 - val_accuracy: 0.7868\n",
      "Epoch 7/20\n",
      "30/30 [==============================] - 2s 68ms/step - loss: 0.4470 - accuracy: 0.8170 - val_loss: 0.4485 - val_accuracy: 0.8032\n",
      "Epoch 8/20\n",
      "30/30 [==============================] - 2s 68ms/step - loss: 0.4099 - accuracy: 0.8364 - val_loss: 0.4218 - val_accuracy: 0.8149\n",
      "Epoch 9/20\n",
      "30/30 [==============================] - 2s 68ms/step - loss: 0.3826 - accuracy: 0.8503 - val_loss: 0.3997 - val_accuracy: 0.8274\n",
      "Epoch 10/20\n",
      "30/30 [==============================] - 2s 69ms/step - loss: 0.3534 - accuracy: 0.8625 - val_loss: 0.3797 - val_accuracy: 0.8342\n",
      "Epoch 11/20\n",
      "30/30 [==============================] - 2s 68ms/step - loss: 0.3322 - accuracy: 0.8728 - val_loss: 0.3624 - val_accuracy: 0.8441\n",
      "Epoch 12/20\n",
      "30/30 [==============================] - 2s 68ms/step - loss: 0.3053 - accuracy: 0.8853 - val_loss: 0.3471 - val_accuracy: 0.8511\n",
      "Epoch 13/20\n",
      "30/30 [==============================] - 2s 67ms/step - loss: 0.2835 - accuracy: 0.8947 - val_loss: 0.3328 - val_accuracy: 0.8590\n",
      "Epoch 14/20\n",
      "30/30 [==============================] - 2s 68ms/step - loss: 0.2628 - accuracy: 0.9037 - val_loss: 0.3216 - val_accuracy: 0.8627\n",
      "Epoch 15/20\n",
      "30/30 [==============================] - 2s 67ms/step - loss: 0.2420 - accuracy: 0.9105 - val_loss: 0.3124 - val_accuracy: 0.8681\n",
      "Epoch 16/20\n",
      "30/30 [==============================] - 2s 68ms/step - loss: 0.2276 - accuracy: 0.9189 - val_loss: 0.3104 - val_accuracy: 0.8713\n",
      "Epoch 17/20\n",
      "30/30 [==============================] - 2s 67ms/step - loss: 0.2148 - accuracy: 0.9231 - val_loss: 0.2999 - val_accuracy: 0.8751\n",
      "Epoch 18/20\n",
      "30/30 [==============================] - 2s 68ms/step - loss: 0.2009 - accuracy: 0.9295 - val_loss: 0.2972 - val_accuracy: 0.8758\n",
      "Epoch 19/20\n",
      "30/30 [==============================] - 2s 67ms/step - loss: 0.1849 - accuracy: 0.9355 - val_loss: 0.2977 - val_accuracy: 0.8766\n",
      "Epoch 20/20\n",
      "30/30 [==============================] - 2s 68ms/step - loss: 0.1781 - accuracy: 0.9405 - val_loss: 0.2906 - val_accuracy: 0.8794\n"
     ]
    }
   ],
   "source": [
    "history = model.fit( train_data.shuffle(10000).batch(512),\n",
    "                     epochs=20,\n",
    "                     validation_data=validation_data.batch(512),\n",
    "                     verbose=1 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49/49 - 1s - loss: 0.3130 - accuracy: 0.8674\n",
      "loss: 0.313\n",
      "accuracy: 0.867\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate( test_data.batch(512), verbose=2 )\n",
    "\n",
    "for name, value in zip(model.metrics_names, results):\n",
    "  print(\"%s: %.3f\" % (name, value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> This fairly naive approach achieves an accuracy of about 87%. With more advanced approaches, the model should get closer to 95%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(EOF)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

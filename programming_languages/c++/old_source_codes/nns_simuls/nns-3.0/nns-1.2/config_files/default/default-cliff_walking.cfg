# default-cliff_walking.cfg
#
# Reinforcement Learning (RL) for the cliff walking problem.
# This is a test problem to implement and test RL.
#
# Refer to p.149 in Sutton & Barto book.
#
# Last updated: Apr. 4, 2011 (Mon)
# First written: May 25, 2009 (Mon)
#
# Examples:
#   No space is allowed a in variable name
#     simul_task_id = 2
#     pso_p_best_initial_value = inf
# Do not use ";" at the end of the line.
#   Examples. The following lines are wrong.
#     simul_task_id = 2;
#     pso_p_best_initial_value = inf;
#
#   For a boolen type variable of which option is limited only to on or off,
# do not use "true" or "false", rather use 0 or 1 unless it's specified.
#
# Refer to the manual for details.

################################################################################
#                           ConfigSimulations                                  #
################################################################################
# Options for possible variables
#
# simul_task_type: 
#  cmlp_string_count, learn_optimal_moves, plot_act_fn_mod_3, test_ter2bin,
#  test_cliff_walking
#    Use "learn_optimal_moves" to train CNN for the Go data.
#    Note: if simul_task_type = plot_act_fn_mod_3, most of the options are disabled.
# simul_boardSize: 2
#   The program is designed only for 2 now.
# simul_trace_all: 0 (off), 1 (on).        Typicall, this is turned off.
# simul_trace_on: 0 (off), 1 (on).         Typicall, this is turned off.
# simul_postprocess: 0 (off), 1 (on).      Typicall, this is turned off.
# simul_show_progress_bar: 0 (off), 1 (on) Typicall, this is turned on.
# simul_player: black, white
#   The input data is separated for black and white Go player.
#   The CNN should be trained separately for each player.
# simul_data_type: single_valued_function, multi_valued_function
# simul_trace4debug: 0 (off), 1 (on).      Typicall, this is turned off.
#   Turn on/off some debugging information into the trace file.

simul_task_type         = test_cliff_walking
simul_show_progress_bar = 1
simul_trace4debug       = 0

# Design issue: simul_boardSize & simul_player may be in a new class ConfigBaduk.
# Leave them because there aren't many variables to configure the Baduk games now.

################################################################################
#                      ConfigReinforcementLearning                             #
################################################################################
# Options for possible variables
#
# file_gnuplot_input
#    a text file with data to plot. Use .dat for file extension.
# file_gnuplot_config
#
# rl_move_option: standard_move, kings_move, kings_move_with_pause
#   This is only for a test problem such as cliff walking and windy grid world.
#
# rl_update_method: sarsa, qlearning
# rl_move_option: greedy, egreedy
#
# rl_reward_structure: in double
#   Rewards of different cases are delimited by column ":".
#   Examples
#     -1.0:-100.0 = "roaming around":"is cliff".

2d_grid_world_size           = 12x4
2d_grid_world_start_position = (0,0)
2d_grid_world_end_position   = (11,0)
2d_grid_world_cliff_pattern  = 1

rl_max_episode               = 20000
rl_reward_structure          = -1.0:-100.0
rl_alpha                     = 0.1
rl_gamma                     = 1.2
rl_epsilon                   = 0.1

#rl_update_method             = qlearning
rl_update_method             = sarsa
rl_move_option               = standard_move
#rl_move_option               = kings_move_with_pause
#rl_move_option               = kings_move
rl_action_criterion          = egreedy
#rl_action_criterion          = greedy

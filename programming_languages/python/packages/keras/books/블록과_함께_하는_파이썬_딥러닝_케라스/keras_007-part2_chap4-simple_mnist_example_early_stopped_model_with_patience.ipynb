{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 700 samples, validate on 300 samples\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'type' object cannot be interpreted as an integer",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-58d05e4f1c3b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[0mepochs_max\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m3000\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m \u001b[0mhist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mEarlyStopping\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m \u001b[0mx_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mearly_stopping\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[1;31m# 5. 학습과정 살펴보기\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\keras\\lib\\site-packages\\keras-2.2.3-py3.6.egg\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\keras\\lib\\site-packages\\keras-2.2.3-py3.6.egg\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    140\u001b[0m             \u001b[0mindices_for_conversion_to_dense\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 142\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    143\u001b[0m         \u001b[1;31m# Reset stateful metrics\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    144\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstateful_metric_functions\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'type' object cannot be interpreted as an integer"
     ]
    }
   ],
   "source": [
    "# keras_007-part2_chap4-simple_mnist_example_early_stopped_model_with_patience\n",
    "#\n",
    "# 김태영, 블록과 함께 하는 파이썬 딥러닝 케라스\n",
    "# Part2. 딥러닝 개념잡기\n",
    "# Chapter4. 학습 조기종료 시키기\n",
    "# 2018-10-04 (목)\n",
    "\n",
    "# p.61, 2. 조기종료 시키기 + patence\n",
    "# 학습 조기종료를 위해서 EarlyStopping()이라는 함수를 사용\n",
    "# 콜백함수란 어떤 함수를 수행 시 그 함수에서 내가 지정한 함수를 호출하는 것을 말함.\n",
    "# 이 예제에서는 fit()함수에서 EarlyStopping() 콜백함수가 학습과정 중에 매번 호출됨.\n",
    "# 지정된 최대 Epoch가 있어도, 학습과정에서 EarlyStopping 콜백함수를 호출하여 해당 조건이 되면 학습을 조기종료 시킵니다.\n",
    "#\n",
    "# EarlyStopping 콜백함수에서 patence인자를 사용합니다.\n",
    "# patience는 개선이 없다고 바로 종료하지 않고, 개선이 없는 에포크를 얼마나 기다려줄 것인가를 설정할 수 있습니다.\n",
    "# 만약 20이라고 지정하면 개선이 없는 에포크가 20번째 지속될 경우 학습을 종료합니다.\n",
    "\n",
    "# 0. 사용할 패키지 불러오기\n",
    "import keras\n",
    "from keras.utils import np_utils\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "import numpy as np\n",
    "\n",
    "#1. 데이터셋 생성하기\n",
    "# 훈련셋과 시험셋 불러오기\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# 훈련셋과 검증셋 분리\n",
    "x_val = x_train[50000:]\n",
    "y_val = y_train[50000:]\n",
    "x_train = x_train[:50000]\n",
    "y_train = y_train[:50000]\n",
    "\n",
    "# 데이터셋 전처리\n",
    "x_train = x_train.reshape(50000,784).astype('float32') / 255.0\n",
    "x_val = x_val.reshape(10000,784).astype('float32') / 255.0\n",
    "x_test = x_test.reshape(10000,784).astype('float32') / 255.0\n",
    "\n",
    "# 훈련셋과 검증셋 고르기\n",
    "# random indexs\n",
    "np.random.seed(3)\n",
    "train_rand_idxs = np.random.choice(5000,700)\n",
    "val_rand_idxs = np.random.choice(10000, 300)\n",
    "\n",
    "x_train = x_train[ train_rand_idxs ]\n",
    "y_train = y_train[ train_rand_idxs ]\n",
    "x_val = x_val[ val_rand_idxs ]\n",
    "y_val = y_val[ val_rand_idxs ]\n",
    "\n",
    "# 라벨데이터 one-hot encoding 처리\n",
    "y_train = np_utils.to_categorical( y_train )\n",
    "y_val = np_utils.to_categorical( y_val )\n",
    "y_test = np_utils.to_categorical( y_test )\n",
    "\n",
    "# 2. 모델 구성하기\n",
    "model = Sequential()\n",
    "model.add( Dense( units = 2, input_dim = 28*28, activation = 'relu') )\n",
    "model.add( Dense( units = 10, activation = 'softmax') )\n",
    "\n",
    "# 3. 모델 학습과정 설정하기\n",
    "model.compile( loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'] )\n",
    "\n",
    "# 4. 모델 학습 시키기\n",
    "from keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping( patience=20 )\n",
    "\n",
    "epochs_max = 3000\n",
    "hist = model.fit( x_train, y_train, epochs = epochs_max, batch_size = 10, validation_data = ( x_val, y_val ), callbacks=[early_stopping])\n",
    "\n",
    "# 5. 학습과정 살펴보기\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, loss_ax = plt.subplots()\n",
    "acc_ax = loss_ax.twinx()\n",
    "\n",
    "loss_ax.plot( hist.history['loss'],'y', label='train loss')\n",
    "loss_ax.plot( hist.history['val_loss'],'r', label='validation loss')\n",
    "loss_ax.plot( hist.history['acc'],'y', label='train accuracy')\n",
    "loss_ax.plot( hist.history['val_acc'],'y', label='validation accuracy')\n",
    "\n",
    "loss_ax.set_xlabel( 'epoch' )\n",
    "loss_ax.set_ylabel( 'loss' )\n",
    "acc_ax.set_ylabel( 'accuracy' )\n",
    "\n",
    "loss_ax.legend( loc = 'upper left' )\n",
    "acc_ax.legend( loc = 'lower left' )\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# 6. 모델 평가하기\n",
    "loss_and_metrics = model.evaluate( x_test, y_test, batch_size = 32 )\n",
    "\n",
    "print('')\n",
    "print('loss : ' + str( loss_and_metrics[0] ) )\n",
    "print('loss : ' + str( loss_and_metrics[1] ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

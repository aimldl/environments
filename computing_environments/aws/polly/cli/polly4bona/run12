#!/bin/bash
OPTION_FORMAT='mp3'
OPTION_VOICE='Joey'
OPTIONS="--output-format ${OPTION_FORMAT} --voice-id ${OPTION_VOICE}"

TEXT="Slide 28 for 4 minutes. A very important point to call out is the simulation to real domain transfer.
We trained our model in a simulated environment. It learned features from the simulated images. We will now attempt to use it in the real world with real world images. The real world doesn’t always look the same as the simulated world. This challenge is the sim-to-real domain transfer challenge. How can we possibly bridge this gap. Pause. 1. Control the environment. Make the simulator and real world seem as close to each other as possible. This is what you will see we have done. Our real-world tracks mimic the simulation environment. 2. Randomize the environment, this allows model to generalize. How can you do this? You change the textures/colors used in the simulation during the training process. This will make the model “insensitive” to the color of the line, and sensitive to a line. Another way would be to randomize physics, or camera field of view. 3. Modularity and abstraction. Swap out parts of the model architecture, for example put a pre-trained model in place that can detect whether the upcoming road is straight, curves left, or curves right. Your model will then train on top of this additional info provided in the image. Slide 29. 13 minutes remaining. So that is a brief overview of RL, the console and reward functions. Let’s wrap-up with a quick discussion of how you can get involved. 
"
FILE_NAME="rl4bona-12.mp3"
CMD="aws polly synthesize-speech ${OPTIONS} --text '${TEXT}' ${FILE_NAME}"
echo $CMD
eval $CMD

#!/bin/bash
OPTION_FORMAT='mp3'
OPTION_VOICE='Joey'
OPTIONS="--output-format ${OPTION_FORMAT} --voice-id ${OPTION_VOICE}"

TEXT="Slide 23 for 4 mins. In the virtual simulator, and in the real world, the state (image) of the track is sent to a reinforcement learning model and this returns the action to take. In AWS DeepRacer the actions are signals sent to the car to control how fast or slow it goes and what angle the steering should point in. The action is selected from the action space in the model. This action space is defined before we start training the model. Once trained you can’t change the action space. Think about the possible actions you take when driving a car, or if you don’t drive when you cycle a bike. You can accelerate to go faster, or brake to slow down, or just maintain your speed, and steer from left to right to change direction, or keep the same direction. We create a list of actions that we think the vehicle should perform during driving. It won’t be capable of doing anything outside of this list of actions. The more actions we provide, obviously the longer it will take to train a model but potentially get a better range of actions. Actions are multiplicative, so 2 speeds and 3 driving angles will give an action space of 6. We also put a throttle limiter on the actual car. This is to protect the car. If your car was train in the simulator at a high speed, first test with caution as you don’t want it to race camera first into a wall. Slide 24. 50 MINUTES. Lab will cover building their first model. Once virtual leaderboards are open then can submit to virtual leaderboards. Slide 25. You have 21 minutes remaining, 9 minutes for Q&A. "
FILE_NAME="rl4bona-10.mp3"
CMD="aws polly synthesize-speech ${OPTIONS} --text '${TEXT}' ${FILE_NAME}"
echo $CMD
eval $CMD

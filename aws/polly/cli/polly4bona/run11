#!/bin/bash
OPTION_FORMAT='mp3'
OPTION_VOICE='Joey'
OPTIONS="--output-format ${OPTION_FORMAT} --voice-id ${OPTION_VOICE}"

TEXT="Slide 26 for 2 minutes. Lift up a car and show them. CAR 18th scale 4WD with monster truck chassis. CPU Intel Atom™ Processor. MEMORY 4GB RAM. STORAGE 32GB (expandable). WI-FI 802.11ac. CAMERA 4 MP camera with MJPEG. SOFTWARE Ubuntu OS 16.04.3 LTS, Intel® OpenVINO™ toolkit, ROS Kinetic. DRIVE BATTERY 1100mAh lithium polymer. COMPUTE BATTERY 13600mAh USB-C PD. PORTS 4x USB-A, 1x USB-C, 1x Micro-USB, 1x HDMI. SENSORS Integrated accelerometer and gyroscope. Slide 27 for 2 minutes. We use ROS v1.0 on top of Ubuntu to power the device. Every time you load a model for autonomous driving in the car, it is optimized by Intel’s OpenVINO model optimizer. During autonomous driving, the pictures flow from the camera through the media engine, into the Intel OpenVINO inference engine, from where the inference results are converted into driving actions (this is the speed and direction), which flows into the control node that converts these to Pulse Width Modulation (PWN) signals that are sent to the engine and steering servo in the car. "
FILE_NAME="rl4bona-11.mp3"
CMD="aws polly synthesize-speech ${OPTIONS} --text '${TEXT}' ${FILE_NAME}"
echo $CMD
eval $CMD

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. CNN (Convolutional Neural Network)\n",
    "\n",
    "* \"시작하세요! 텐서플로우 2.0 프로그래밍\", \n",
    "  * 6. 컨볼루션 신경망, p.139\n",
    "  * 6.1. 특징 추출, pp.139-142\n",
    "  * 6.2. 주요 레이어 정리, pp.142-150\n",
    "  * 6.5. 정리, p.173"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 배경 지식\n",
    "### 디지털 세계에서 색의 표현\n",
    "[Channel (digital image)](https://en.wikipedia.org/wiki/Channel_(digital_image))\n",
    "* RGB image: Red, Green, Blue\n",
    "* YUV image: Luma (brightness, Y) & chrominance (color, U, V) components; Y (luma), U (Blue projection), V (Red projection)\n",
    "* CMYK image: Cyan, Magenta, Yellow, blacK\n",
    "* HSV image: Hue, Saturation, Value\n",
    "\n",
    "RGB Image는 빨강, 초록, 파랑의 삼원색으로 된 세 개의 채널이 있습니다.\n",
    "\n",
    "출처: [How to convert rgb to YCbCr?](https://mathematica.stackexchange.com/questions/29786/how-to-convert-rgb-to-ycbcr)\n",
    "<img src='images/digital_image_channels-rgb2ycbcr.png' align='left'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1. 특징 추출\n",
    "오랜 기간동안 이미지 데이터는 숫자나 2차원인 표로 된 Formatted data에 비해 다루기 어려웠습니다. 왜냐하면 표로 된 Wine Dataset의 경우 와인의 종류나 품질을 예측하기 위한 특징 (당도, 알코올 도수 등)이 데이터에 있습니다. 이미지는 연구자가 특징을 찾아야했습니다. 이렇게 수작업으로 특징을 설계하기 위한 세가지 문제가 있습니다.\n",
    "1. 적용 분야에 대한 전문 지식이 필요\n",
    "2. 수작업 설계는 시간과 비용이 많이 소요\n",
    "3. 한 분야에서 효과적인 특징을 다른 분야에 적용하기 힘들다.\n",
    "\n",
    "CNN은 분류기 앞의 Convolutional Network 부분이 특징을 학습하기 때문에, 특징을 추출하는 필터를 자동으로 생성한다고 이해할 수 있습니다. CNN이 대중화되고 난 이후에는 이미지 문제를 푸는 다양한 산업계의 문제가 서비스/상용화 되었습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hand-Crafted Feature (수작업한 특징)\n",
    "* SIFT (Scale-Invariant Feature Transform): 이미지의 회전과 크기에 대해 변하지 않는 특징을 추출해서 두 개의 이미지에서 서로 대응하는 부분을 찾아냅니다.\n",
    "* Canny Edge Detection, 외곽선 검출 알고리즘 중의 하나\n",
    "\n",
    "Filter or Kernel\n",
    "* 수직선 검출\n",
    "* 수평선 검출\n",
    "* Box Blur\n",
    "* Sharpen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2. 주요 레이어 정리\n",
    "\n",
    "CNN은 분류기 (Classifier) 앞에 특징 추출기 (Feature Extractor)가 있는 구조를 가집니다. Feature Extractor의 출력을 Classifier에 맞추기 위해 Flat Layer가 있습니다.\n",
    "\n",
    "> CNN의 구조 = Feature Extractor - Flat Layer - Classifier\n",
    "\n",
    "* Feature Extractor는 Convolution Layer, Pooling Layer로 구성이 됩니다.\n",
    "* Classifier는 Fully-Connected Network (FCN)라고도 불리는데, Dense Layer가 사용됩니다. 마지막 Dense Layer를 제외하고는, Dense Layer 사이에 과적합을 막기 위한 Dropout Layer가 배치됩니다.\n",
    "\n",
    "* 정리하자면 CNN을 구성하는 레이어 중 소중한 것은 세 가지가 있습니다.\n",
    "  * 컨볼루션 레이어\n",
    "  * 풀링 레이어\n",
    "  * 드롭아웃 레이어\n",
    "* 이 중 컨볼루션 레이어의 값만 학습이 되고, 나머지 2개는 학습이 되지 않습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2.1. 컨볼루션 레이어 (Convolution Layer)\n",
    "* 각 RGB image에는 세 개의 채널이 있고, Convolution Layer는 각 채널에 대해 계산된 값의 합으로 새로운 이미지를 만듭니다.\n",
    "* 일반적으로 CNN은 여러개의 Convolution Layer를 쌓으면서 뒤로 갈수록 필터의 수를 늘리기 때문에 이미지의 마지막 차원수는 점점 늘어납니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> conv1 = tf.keras.layers.Conv2D( kernel_size=(3,3), strides=(2,2), padding='valid', filters=16 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* kernel_size: 커널의 크기, 혹은 필터 행렬의 크기, 혹은 수용 영역 (Receptive field)라고 불립니다.\n",
    "* strides:  필터 계산 과정에서 건너 뛰는 정도 혹은 스텝마다 이동하는 크기 입니다.\n",
    "  * 기본값 (1,1)는 한 칸씩 슬라이드해서 계산\n",
    "  * (2,2)는 두 칸씩 슬라이드하므로 한 칸씩 건너 뛰는 것과 같습니다.\n",
    "* padding: 채워넣기. 입력 이미지 주변에 빈 값을 채워넣을 지 정합니다.\n",
    "  * 'valid': 빈 값 안 씀\n",
    "  * 'same': 출력 이미지의 크기를 입력 이미지와 같도록 만듭니다.\n",
    "    * 채워 넣을 값으로 0이 쓰이면 Zero padding이라고 합니다.\n",
    "* filters: 필터의 개수. \n",
    "  * 필터의 개수가 클 수록 추출하는 특징이 많아지지만, 그만큼 연산량이 높아서 학습속도가 높아집니다.\n",
    "  * 필터가 너무 많으면 과적합이 발생할 수도 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2.2. 풀링 레이어 (Pooling Layer)\n",
    "* Max pooling layer\n",
    "  * max pooling이 더 많이 쓰입니다.\n",
    "  \n",
    "> pool1 = tf.keras.layers.MaxPool2D( pool_size(2,2), strides=(2,2) )\n",
    "\n",
    "* pool_size: 이 범위의 사각형에서 최대값만 남깁니다.\n",
    "* strides: 건너뛰는 범위. Convolution layer와 동일하게 동작함."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Average pooling layer\n",
    "\n",
    "* 이미지의 인접 픽셀은 비슷한 정보를 가지는 경우가 많다는 특성이 있습니다.\n",
    "* 이미지의 픽셀을 주기적으로 드문드문 뽑아내는 서브 샐플링 (sub-sampling)기법을 적용하면, 이미지의 중요한 정보는 남기되 크기를 줄일 수 있습니다.\n",
    "* 계산량이 줄어들어 과적합을 완화하는 효과도 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2.3. 드롭아웃 레이어 (Dropout Layer)\n",
    "* 학습할 때 무작위로 뉴런의 일부를 떨궈내는, 즉 제거하는 것을 Dropout이라고 합니다.\n",
    "* 이 과정에서 네트워크의 과적합을 막는 효과가 있습니다.\n",
    "\n",
    "> pool1 = tf.keras.layers.Dropout( rate=0.3 )\n",
    "\n",
    "* rate는 제거할 뉴런의 비율 입니다. 0.3이면 30%를 랜덤하게 제거합니다.\n",
    "* 가중치가 없으므로 학습이 되지 않습니다.\n",
    "\n",
    "* Dropout에 대한 직관을 소개합니다.\n",
    "\n",
    "> 나는 은행에 갔다. 창구 직원이 계속 바뀌어서 그 이유를 물어보자, 그들은 이유는 모르겠지만 어쨌든 인사 이동이 많다고 했다. 아마도 직원들 간의 협력이 은행에서 부정을 저지를 수 있기 때문에 그것을 막기 위한 조치라고 생각되었다. 이 사실은 나에게 학습 과정에서 무작위로 뉴런의 부분 집합을 제거하는 것이 뉴런들간의 공모 (Conspiracy)를 막고 과정합 (Overfitting)을 감소시킬 것이라고 깨닫게 했다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
